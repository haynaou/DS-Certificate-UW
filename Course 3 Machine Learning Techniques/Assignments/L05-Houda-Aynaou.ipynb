{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 05 Assignement\n",
    "# Houda Aynaou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workplace Scenario\n",
    "\n",
    "Rooney's client is a tech-manufacturing startup working on a number of automated detection devices for the medical and construction industries. Among the auto-detection devices is a reader that looks at possible carcinoma tissue samples to classify the sample as either benign or malignant. Rooney asks you for help in developing a better algorithm than the current classifier, perhaps a decision tree can help.\n",
    "\n",
    "For this assignment, you will be designing an experiment using decision tree classifiers for the detection of breast cancer and comparing the accuracy using [Breast Cancer Wisconsin Data Set](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)).\n",
    "\n",
    "| Column                    |Description      |\n",
    "|---------------------------|-----------------|\n",
    "|Sample code number         | id number       |\n",
    "|Clump Thickness            | 1 - 10 |     \n",
    "|Uniformity of Cell Size    | 1 - 10 |\n",
    "|Uniformity of Cell Shape   | 1 - 10 |\n",
    "|Marginal Adhesion          | 1 - 10 |\n",
    "|Single Epithelial Cell Size| 1 - 10 |\n",
    "|Bare Nuclei                | 1 - 10 |\n",
    "|Normal Nucleoli            | 1 - 10 |\n",
    "|Mitosis                    | 1 - 10 |\n",
    "|Class                      | 4 for malignant, 2 for benign |\n",
    "\n",
    "\n",
    "\n",
    "## To do\n",
    "\n",
    "1. Test both entropy and the gini coefficient. Which performs better and why?\n",
    "2. What are the best hyperparameter settings for both?\n",
    "3. Visualize both models and see which feature is selected for each criterion. Are they same for both? Why or why not? \n",
    "4. Determine the AUC for the best model you can achieve. What are the precision and recal values and which might be the one you want to maximize?\n",
    "5. What are the implications of using this type of machine learning algorithm for breast cancer analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LINK = 'https://raw.githubusercontent.com/houdaaynaou/DS-Certificate-UW/master/Course%203%20Machine%20Learning%20Techniques/Data/breast-cancer-wisconsin.csv'\n",
    "col_names = ['ID', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitosis' , 'Class']\n",
    "\n",
    "data = pd.read_csv(LINK, names= col_names)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Inspecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting 'Bare Nuclei' column:\n",
    "\n",
    "print(\"'Bare Nuclei' unique observations:\\n\", data['Bare Nuclei'].unique())\n",
    "\n",
    "print('\\nNumber of rows with missing value:', data[data['Bare Nuclei'] == '?'].shape[0])\n",
    "\n",
    "print('\\nObservations with \"Bare Nuclei\" missing values:')\n",
    "\n",
    "data[data['Bare Nuclei'] == '?']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the data features are numerical type except for `Bare Nuclei` column that is object because it contains missing values marked as `?`. Missing values will be handled before building the Decision tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary of the data shows that most features are right skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Histogram of column features\n",
    "sns.set()\n",
    "for col in list(data.drop(['ID', 'Class'], axis=1).columns):\n",
    "    data[col].hist()\n",
    "    plt.title('Histogram of '+ col)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Target variable:\n",
    "sns.set()\n",
    "data['Class'].hist()\n",
    "plt.title('Histogram of Tumor Class')\n",
    "plt.show()\n",
    "\n",
    "print(data['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contain **458** observations from **class 2** *benign tumor* which is twice the observations from **class 4** *malignant tumor*. This is an indicator of class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Handeling missing value in column Bare Nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median \n",
    "bare_median = np.median(pd.to_numeric(data[data['Bare Nuclei'] != '?']['Bare Nuclei']))\n",
    "\n",
    "# Imputing missing value\n",
    "missing = data['Bare Nuclei'] == '?'\n",
    "data.loc[missing, 'Bare Nuclei'] = bare_median\n",
    "\n",
    "# Coerce Column to numeric \n",
    "data['Bare Nuclei'] = pd.to_numeric(data['Bare Nuclei'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Decision Tree Classifier Model\n",
    "## 2.1. Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(['ID', 'Class'], axis = 1)\n",
    "Y = data['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 42, test_size = 0.3)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Geni Coefficient Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Geni coefficient Model\n",
    "gini_tree = DecisionTreeClassifier(criterion= 'gini', random_state= 42)\n",
    "gini_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "pred = gini_tree.predict(X_test)\n",
    " \n",
    "# Model performance\n",
    "confusion_matrix(y_test, pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree with Gini coefficient as a splitting criterion performed fairly well, classifying 60 out of 67 as having melignant breast cancer and 139 out of 143 as having benign bread cancer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Entropy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_tree = DecisionTreeClassifier(criterion= 'entropy', random_state= 42)\n",
    "entropy_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "entropy_pred = entropy_tree.predict(X_test)\n",
    " \n",
    "# Model performance\n",
    "confusion_matrix(y_test, entropy_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree with Gini coefficient as a splitting criterion performed fairly well, classifying 59 out of 67 as having melignant breast cancer and 137 out of 143 as having benign bread cancer. \n",
    "\n",
    "Decision tree with gini coefficient performed better than decision tree with entropy as a criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. GridSearch for best hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 GridSearch for Gini_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "gini_tree = DecisionTreeClassifier(criterion= 'gini', random_state=42)\n",
    "depths = np.arange(1, 10)\n",
    "num_leafs = [1, 5, 10, 20]\n",
    "\n",
    "param_grid = [{'max_depth':depths,\n",
    "              'min_samples_leaf':num_leafs}]\n",
    "\n",
    "# Gini Gridsearch\n",
    "gini_gs = GridSearchCV(estimator = gini_tree, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters\n",
    "gini_gs.fit(X_train, y_train)\n",
    "gini_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predictions:\n",
    "pred_gini_cv = gini_gs.predict(X_test)\n",
    "\n",
    "# performance:\n",
    "print('Confusion matrix with the best found parameters:\\n',confusion_matrix(y_test, pred_gini_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree with Gini coefficient as a splitting criterion improved with best parameters detecting 61 with malignant breast cancer out of 67."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 GridSearch for entropy tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entropy_pipe_tree = DecisionTreeClassifier(random_state=42)\n",
    "depths = np.arange(1, 10)\n",
    "num_leafs = [1, 5, 10, 20]\n",
    "ent_param_grid = [{'max_depth':depths,\n",
    "              'min_samples_leaf':num_leafs}]\n",
    "\n",
    "# entropy Gridsearch\n",
    "entropy_gs = GridSearchCV(estimator= entropy_pipe_tree, param_grid=ent_param_grid, cv=10)\n",
    "\n",
    "entropy_cv = entropy_gs.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters:\n",
    "entropy_cv.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predictions:\n",
    "pred_entropy_cv = entropy_cv.predict(X_test)\n",
    "\n",
    "# performance:\n",
    "print('Confusion matrix with the best found parameters:\\n',confusion_matrix(y_test, pred_entropy_cv))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree with entropy as a splitting criterion improved also with best parameters detecting 61 with malignant breast cancer out of 67. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualizing Trees \n",
    "\n",
    "## 3.1 Gini Coefficient Model Tree with best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Training Decision tree model with gini coefficient and best parameters\n",
    "gini_best_param = DecisionTreeClassifier(criterion= 'gini', max_depth= 4, min_samples_leaf= 1, random_state=42)\n",
    "gini_best_param.fit(X_train, y_train)\n",
    "export_graphviz(gini_best_param,'gini_tree.dot', feature_names = list(X.columns))\n",
    "\n",
    "# predictions\n",
    "gini_best_param_pred = gini_best_param.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from graphviz import render\n",
    "render('dot', 'png', 'gini_tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('gini_tree.dot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Entropy Model Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Training Decision tree model with entropy and best parameters\n",
    "entropy_best_param = DecisionTreeClassifier(criterion= 'entropy', max_depth= 4, min_samples_leaf= 1, random_state=42)\n",
    "entropy_best_param.fit(X_train, y_train)\n",
    "export_graphviz(entropy_best_param,'entropy_tree.dot', feature_names = list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render('dot', 'png', 'entropy_tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Image('entropy_tree.dot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split feature at the root node of the tree selected by both model is `Uniformity of Cell size`, going further down the tree both models differe on the features to split by. \n",
    "Gini coefficient minizine is the probability of a random sample being classified incorrectly if we randomly pick a label according to the distribution in a branch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. AUC, Precision and Recall of the best model: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 AUC for the Geni coefficient model with best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import  metrics \n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, gini_best_param_pred, pos_label=2)\n",
    "\n",
    "# Auc\n",
    "print('Auc:', metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is measured by the area under the ROC curve which depends on how well the test separates the group being tested into those with and without the disease in question. An area of 1 represents a perfect test; an area of .5 represents a worthless test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Precision and recal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Classification report for Geni coefficient model with best parameters:\\n\\n',metrics.classification_report(y_test, gini_best_param_pred, target_names=('2', '4')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which metric to maximize? Precision or Recall?** \n",
    "\n",
    "The metric to maximize is Recall: the proportion of actual positives that are correctly identified as such, meaning the percentage of women with breast canser who are correctly identified as having the condition and minimize false negatives which are errors in which the test result improperly indicates no presence of a cancer breast (the result is negative), when in reality it is present.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Implications of using Decision Tree for breat canser analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees have been used in different areas of medical decision making, they are a reliable and effective decision making technique that provide high classification accuracy with a simple representation of gathered knowledge. This technique has ability of detecting very similarities/differences that a human analyst may be not notice and therefore create and introduction more accurate/useful categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
